<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gesture Recognition with USB Camera</title>
        <link rel="stylesheet" type="text/css"
          href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.1/css/font-awesome.min.css"/>
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/showdown@2.1.0/dist/showdown.min.js"></script>
    <script>window.jQuery || document.write('<script src="{{url_for('static', filename='jquery.js') }}">\x3C/script>')</script>
{#        <script src="https://aframe.io/releases/1.0.0/aframe.min.js"></script>#}
    <!-- we import arjs version without NFT but with marker + location based support -->
{#    <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js"></script>#}
    <link rel="shortcut icon" href="{{ url_for('static', filename='favicon.ico') }}">
    <link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500" rel="stylesheet">
    {#{{ url_for('static', filename='hamburger2.css') }}#}
   <link rel="stylesheet" href="/static/hamburger2.css">
    <link rel="stylesheet" href="/static/styles.css">
    <link rel="stylesheet" href="/static/style.css">
    <style>
        #video, #renderCanvas {
            width: 640px;
            height: 480px;
            {#position: absolute;#}
            {#top: 100px;#}
            {#left: 100px;#}
        }
        #renderCanvas {
            position: absolute;
            top: 100px;
            left: 0;
        }
    </style>

    <script>
        (function(){
            // Ensure fresh load of local MediaPipe libs each page visit
            const ts = Date.now();
            function addScript(src){
                var s=document.createElement('script');
                s.src=src + (src.indexOf('?')===-1?('?v='+ts):('&v='+ts));
                s.defer=false; // load immediately in order
                document.write(s.outerHTML);
            }
            addScript('/static/js/camera_utils.js');
            addScript('/static/js/hands.js');
        })();
    </script>
    <script src="https://cdn.babylonjs.com/babylon.js"></script>
{#    <script src="/static/js/babylon.js"></script>#}
    <script src="https://docs.opencv.org/4.5.5/opencv.js"></script>
{#    <script src="/static/js/opencv.js"></script>#}
</head>
<body style="background-color:black">
    {% include 'menu.html' %}
    <br/><br/><br/>
    <video id="video" autoplay></video>
    <canvas id="renderCanvas"></canvas>
    <canvas id="cvCanvas" width="640" height="480" style="display:none;"></canvas>

    <div id="target_div">Watch this space...</div>
    <div id="messageContainer_div">Message Container</div>

<!--
    div over canvas -- http://jsfiddle.net/n992V/
    https://stackoverflow.com/questions/15861485/placing-a-div-over-a-canvas-in-html5
-->
    <div class="gamecontainer" style="display:table-row;background-color:transparent;margin-left:300px">
        <div id="gamestartscreen">
            {%  include 'displaySection.html' %}
        </div>
    </div>

{#    <h1><a href="//webrtc.github.io/samples/" title="WebRTC samples homepage">WebRTC samples</a><span>Select sources &amp; outputs</span>#}
{#    </h1>#}
{##}
{#    <p>Get available audio, video sources and audio output devices from <code>mediaDevices.enumerateDevices()</code>#}
{#        then set the source for <code>getUserMedia()</code> using a <code>deviceId</code> constraint.</p>#}
{#    <p><b>Note:</b> without permission, the browser will restrict the available devices to at most one per type.</p>#}
{##}
{#    <div class="select">#}
{#        <label for="audioSource">Audio input source: </label><select id="audioSource"></select>#}
{#    </div>#}
{##}
{#    <div class="select">#}
{#        <label for="audioOutput">Audio output destination: </label><select id="audioOutput"></select>#}
{#    </div>#}
{##}
{#    <div class="select">#}
{#        <label for="videoSource">Video source: </label><select id="videoSource"></select>#}
{#    </div>#}
{##}
{#    <div class="select">#}
{#        <label for="objectType">Object type: </label>#}
{#        <select id="objectType">#}
{#            <option value="face" selected>face</option>#}
{#            <option value="bottle">bottle</option>#}
{#            <option value="phone">phone</option>#}
{#        </select>#}
{#    </div>#}

{#    <video id="video" playsinline autoplay></video>#}
{##}
{#    <p><b>Note:</b> If you hear a reverb sound your microphone is picking up the output of your#}
{#        speakers/headset, lower the volume and/or move the microphone further away from your speakers/headset.</p>#}

    <h1 id="hellomarkdown">hello here</h1>

    <script>
        var converter = new showdown.Converter();
        var text      = '# hello, markdown!';
        var html      = converter.makeHtml(text);
        document.getElementById("hellomarkdown").innerHTML = html;//markdown(text);
    </script>

    <script>
        // Video and canvas setup
        const video = document.getElementById('video');
        const cvCanvas = document.getElementById('cvCanvas');
        const ctx = cvCanvas.getContext('2d');


        // Function to select and start webcam stream
        async function startWebcam() {
            try {
                // Request initial permission to access any camera
                const initialStream = await navigator.mediaDevices.getUserMedia({ video: true });
                // Stop the initial stream to free up the camera
                initialStream.getTracks().forEach(track => track.stop());

                // Enumerate devices to get camera list
                const devices = await navigator.mediaDevices.enumerateDevices();
                const videoDevices = devices.filter(device => device.kind === 'videoinput');

                // Find USB camera (look for "USB" in label, case-insensitive)
                let usbCamera = videoDevices.find(device => device.label.toLowerCase().includes('usb'));
                if (!usbCamera) {
                    console.warn('No USB camera found, falling back to default camera');
                    usbCamera = videoDevices[0]; // Fallback to first available camera
                }

                // Start stream with selected camera
                if (usbCamera) {
                    const stream = await navigator.mediaDevices.getUserMedia({
                        video: { deviceId: { exact: usbCamera.deviceId } }
                    });
                    video.srcObject = stream;
                    console.log('Using camera:', usbCamera.label || 'Unknown');
                } else {
                    console.error('No video devices available');
                }
            } catch (error) {
                console.error('Error accessing webcam:', error);
            }
        }

        // Start the webcam
        startWebcam();

        // BabylonJS setup
        const canvas = document.getElementById('renderCanvas');
        const engine = new BABYLON.Engine(canvas, true);
        const scene = new BABYLON.Scene(engine);
        scene.clearColor = new BABYLON.Color4(0, 0, 0, 0);

        const camera = new BABYLON.FreeCamera('camera', new BABYLON.Vector3(0, 0, -10), scene);
        camera.setTarget(BABYLON.Vector3.Zero());

        const light = new BABYLON.HemisphericLight('light', new BABYLON.Vector3(0, 1, 0), scene);

        // Object manager for multiple detected objects (e.g., faces)
        const objects = new Map(); // id -> { mesh, material, grabOffset, lastAngle }
        let activeObjectId = null; // id of the currently interacted object

        // Object type dropdown handling (declared after 'objects' to avoid TDZ issues)
        const objectSelect = document.getElementById('objectType');
        let selectedObjectType = (objectSelect && objectSelect.value) ? objectSelect.value : 'face';
        if (objectSelect) {
            objectSelect.addEventListener('change', () => {
                selectedObjectType = objectSelect.value;
                // Hide meshes that are not of the selected type and reset active object if it doesn't match
                objects.forEach(({ mesh }, id) => {
                    if (!id.startsWith(`${selectedObjectType}_`)) {
                        mesh.isVisible = false;
                    }
                });
                if (activeObjectId && !activeObjectId.startsWith(`${selectedObjectType}_`)) {
                    activeObjectId = null;
                }
                console.log('Selected object type:', selectedObjectType);
            });
        }

        function getOrCreateObject(id) {
            if (objects.has(id)) return objects.get(id);
            const mesh = BABYLON.MeshBuilder.CreatePlane(id, { size: 1 }, scene);
            const material = new BABYLON.StandardMaterial(`mat_${id}`, scene);
            material.diffuseColor = new BABYLON.Color3(1, 1, 1);
            mesh.material = material;
            mesh.billboardMode = BABYLON.Mesh.BILLBOARDMODE_ALL;
            mesh.isVisible = false;
            const entry = { mesh, material, grabOffset: new BABYLON.Vector3(0, 0, 0), lastAngle: null };
            objects.set(id, entry);
            return entry;
        }

        // Gesture state
        let currentGesture = 'none';
        let isGrabbing = false;
        let wasGrabbing = false;

        // Render loop with gesture-based color change for active object only
        engine.runRenderLoop(() => {
            // Reset all objects to white each frame
            objects.forEach(({ material, mesh }, id) => {
                if (mesh.isVisible) {
                    material.diffuseColor = new BABYLON.Color3(1, 1, 1);
                }
            });
            // Apply gesture color to active object
            if (activeObjectId && objects.has(activeObjectId)) {
                const { material, mesh } = objects.get(activeObjectId);
                if (mesh.isVisible) {
                    switch (currentGesture) {
                        case 'fist':
                            material.diffuseColor = new BABYLON.Color3(1, 0, 0); // Red
                            break;
                        case 'open':
                            material.diffuseColor = new BABYLON.Color3(0, 1, 0); // Green
                            break;
                        case 'two_fingers':
                            material.diffuseColor = new BABYLON.Color3(0, 0, 1); // Blue
                            break;
                        default:
                            material.diffuseColor = new BABYLON.Color3(1, 1, 1); // White
                    }
                }
            }
            scene.render();
        });

        // Coordinate mapping
        const videoWidth = 640;
        const videoHeight = 480;
        const sceneWidth = 6;
        const sceneHeight = 4.5;

        function mapToScene(x, y) {
            const sceneX = (x / videoWidth) * sceneWidth - sceneWidth / 2;
            const sceneY = -((y / videoHeight) * sceneHeight - sceneHeight / 2);
            return [sceneX, sceneY];
        }

        // Distance calculation in 2D (x, y) for simplicity
        function distance(p1, p2) {
            return Math.sqrt((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2);
        }
        function distanceXY(x1, y1, x2, y2) {
            return Math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2);
        }

        function getNearestObject(cursorVec3, maxDist = 1.0) {
            let nearestId = null;
            let nearestDist = Infinity;
            objects.forEach(({ mesh }, id) => {
                if (!mesh.isVisible) return;
                const dx = mesh.position.x - cursorVec3.x;
                const dy = mesh.position.y - cursorVec3.y;
                const d = Math.hypot(dx, dy);
                if (d < nearestDist && d <= maxDist) {
                    nearestDist = d;
                    nearestId = id;
                }
            });
            return nearestId;
        }

        // Hand gestures moved to external module

        // OpenCV.js face detection
        let classifier;
        cv['onRuntimeInitialized'] = async () => {
            const response = await fetch('https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml');
            {#const response = await fetch('/static/opencv/haarcascade_frontalface_default.xml');#}
            const buffer = await response.arrayBuffer();
            cv.FS_createDataFile('/', 'cascade.xml', new Uint8Array(buffer), true, false, false);
            classifier = new cv.CascadeClassifier();
            classifier.load('cascade.xml');
            detectFaces();
        };

        function detectFaces() {
            ctx.drawImage(video, 0, 0, 640, 480);
            const imageData = ctx.getImageData(0, 0, 640, 480);
            const src = cv.matFromImageData(imageData);
            cv.cvtColor(src, src, cv.COLOR_RGBA2GRAY);
            const faces = new cv.RectVector();
            classifier.detectMultiScale(src, faces);

            {#cv.flip(src, 1);#}

            // This calculation TODO: will determine object distance and then create a calculated amount of pixels to
            //    move the box up to the top of the item
            const calculation =  - 250;


            if (faces.size() > 0) {
                const seenIds = new Set();
                for (let i = 0; i < faces.size(); i++) {
                    const face = faces.get(i);
                    const centerX = face.x + face.width / 2;
                    const centerY = face.y - face.height;
                    const [sceneX, sceneY] = mapToScene(centerX, centerY);
                    const id = `${selectedObjectType}_${i}`;
                    const entry = getOrCreateObject(id);
                    // Only update from face detection when not actively grabbing this object
                    if (!(isGrabbing && activeObjectId === id)) {
                        entry.mesh.position.set(sceneX, sceneY, 0);
                    }
                    entry.mesh.isVisible = true;
                    seenIds.add(id);
                }
                // Hide face objects not seen in this frame (unless being grabbed)
                objects.forEach(({ mesh }, id) => {
                    if (id.startsWith(`${selectedObjectType}_`) && !seenIds.has(id)) {
                        if (!(isGrabbing && activeObjectId === id)) {
                            mesh.isVisible = false;
                        }
                    }
                });
            } else {
                // No faces: hide all objects of the selected type unless being grabbed
                objects.forEach(({ mesh }, id) => {
                    if (id.startsWith(`${selectedObjectType}_`)) {
                        if (!(isGrabbing && activeObjectId === id)) {
                            mesh.isVisible = false;
                        }
                    }
                });
            }

            src.delete();
            faces.delete();
            requestAnimationFrame(detectFaces);
        }
    </script>

    <script src="/static/js/hand_gestures.js"></script>
    <script>
        // Initialize hand/gesture module after globals are defined
        if (typeof initHands === 'function') {
            initHands();
        } else {
            console.error('initHands() is not available.');
        }
    </script>

    <script src="/static/js/adapter-latest.js"></script>
{#    <script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>#}

{#    <script src="/static/js/hands_solution_packed_assets_loader.js" crossorigin="anonymous"></script>#}
{#    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands_solution_packed_assets_loader.js" crossorigin="anonymous"></script>#}

    {#    <script src="/static/js/hands_solution_simd_wasm_bin.js" crossorigin="anonymous"></script>#}
{#    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands_solution_simd_wasm_bin.js" crossorigin="anonymous"></script>#}

    <script src="/static/main.js" async></script>

{% include 'javascript.html' %}
<script type="text/javascript">
    {% for item in javascriptList %}
        {% include item %}
    {% endfor %}
</script>
</body>
</html>